{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedPythonError",
     "evalue": "It seems your Julia and PyJulia setup are not supported.\n\nJulia executable:\n    julia\nPython interpreter and libpython used by PyCall.jl:\n    /usr/bin/python3\n    /usr/lib/x86_64-linux-gnu/libpython3.10.so.1.0\nPython interpreter used to import PyJulia and its libpython.\n    /usr/bin/python3\n    /usr/lib/x86_64-linux-gnu/libpython3.10.so.1.0\n\nYour Python interpreter \"/usr/bin/python3\"\nis statically linked to libpython.  Currently, PyJulia does not fully\nsupport such Python interpreter.\n\nThe easiest workaround is to pass `compiled_modules=False` to `Julia`\nconstructor.  To do so, first *reboot* your Python REPL (if this happened\ninside an interactive session) and then evaluate:\n\n    >>> from julia.api import Julia\n    >>> jl = Julia(compiled_modules=False)\n\nAnother workaround is to run your Python script with `python-jl`\ncommand bundled in PyJulia.  You can simply do:\n\n    $ python-jl PATH/TO/YOUR/SCRIPT.py\n\nSee `python-jl --help` for more information.\n\nFor more information, see:\n\n    https://pyjulia.readthedocs.io/en/latest/troubleshooting.html\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedPythonError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19370/3451922862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(sys.path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLMORL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDQNHybrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDQNHybrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmo_gymnasium\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmo_gym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHubProjects/LMORL/LMORL/BAN/API/agents/DQNHybrid.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLMORL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjulia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJulia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjulia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHubProjects/LMORL/LMORL/BAN/API/agents/agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjulia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJulia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjulia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/julia/core.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjuliapath\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Main'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             return sys.modules.setdefault(fullname,\n\u001b[0;32m--> 247\u001b[0;31m                                           JuliaMainModule(self, fullname))\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjulia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misafunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjuliapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjulia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjuliapath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/julia/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJuliaModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_julia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjulia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__loader__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/julia/core.py\u001b[0m in \u001b[0;36mjulia\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjulia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjulia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjulia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJulia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjulia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/julia/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, init_julia, jl_init_path, runtime, jl_runtime_path, debug, **julia_options)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0muse_custom_sysimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             ):\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedPythonError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjlinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_julia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnsupportedPythonError\u001b[0m: It seems your Julia and PyJulia setup are not supported.\n\nJulia executable:\n    julia\nPython interpreter and libpython used by PyCall.jl:\n    /usr/bin/python3\n    /usr/lib/x86_64-linux-gnu/libpython3.10.so.1.0\nPython interpreter used to import PyJulia and its libpython.\n    /usr/bin/python3\n    /usr/lib/x86_64-linux-gnu/libpython3.10.so.1.0\n\nYour Python interpreter \"/usr/bin/python3\"\nis statically linked to libpython.  Currently, PyJulia does not fully\nsupport such Python interpreter.\n\nThe easiest workaround is to pass `compiled_modules=False` to `Julia`\nconstructor.  To do so, first *reboot* your Python REPL (if this happened\ninside an interactive session) and then evaluate:\n\n    >>> from julia.api import Julia\n    >>> jl = Julia(compiled_modules=False)\n\nAnother workaround is to run your Python script with `python-jl`\ncommand bundled in PyJulia.  You can simply do:\n\n    $ python-jl PATH/TO/YOUR/SCRIPT.py\n\nSee `python-jl --help` for more information.\n\nFor more information, see:\n\n    https://pyjulia.readthedocs.io/en/latest/troubleshooting.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path(os.getcwd())\n",
    "\n",
    "if str(root_dir.parents[1]) not in sys.path:\n",
    "  sys.path.append(str(root_dir.parents[1]))\n",
    "\n",
    "#print(sys.path)\n",
    "\n",
    "from LMORL.BAN.API.agents.DQNHybrid import DQNHybrid\n",
    "\n",
    "import mo_gymnasium as mo_gym\n",
    "\n",
    "env = mo_gym.make(\"mo-lunar-lander-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size = env.observation_space.shape[0]\n",
    "num_actions = int(env.action_space.n)\n",
    "action_space = list(range(env.action_space.n))\n",
    "learning_rate = 0.001\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.1\n",
    "batch_size = 64\n",
    "train_start = 64\n",
    "hidden_size = 128\n",
    "BAN_SIZE = 3\n",
    "max_memory_size=2000\n",
    "\n",
    "agent = DQNHybrid(input_size=input_size, num_actions=num_actions,\n",
    "                  action_space=action_space, learning_rate=learning_rate,\n",
    "                  epsilon_decay=epsilon_decay, epsilon_min=epsilon_min,\n",
    "                  batch_size=batch_size, hidden_size=hidden_size,\n",
    "                  ban_size=3, max_memory_size=max_memory_size, train_start=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:21:09\tEpisode\t1\ttimesteps:\t74\tTook\t1.270426 sec - reward:\t[-100.0, -140.27313774824142, -20.0]\t| 100AvgReward: [-100.0, -140.27313774824142, -20.0]\n",
      "experience_replay! took 16.35996 seconds\n",
      "19:21:26\tEpisode\t2\ttimesteps:\t74\tTook\t16.524599 sec - reward:\t[-100.0, -191.8354700654745, -21.0]\t| 100AvgReward: [-100.0, -166.05430390685797, -20.5]\n",
      "19:21:26\tEpisode\t3\ttimesteps:\t59\tTook\t0.170663 sec - reward:\t[-100.0, 0.33456916362047195, -9.0]\t| 100AvgReward: [-100.0, -110.59134621669848, -16.666666666666668]\n",
      "19:21:26\tEpisode\t4\ttimesteps:\t62\tTook\t0.235497 sec - reward:\t[-100.0, -8.953988822177052, -14.0]\t| 100AvgReward: [-100.0, -85.18200686806813, -16.0]\n",
      "19:21:27\tEpisode\t5\ttimesteps:\t102\tTook\t0.26388 sec - reward:\t[-100.0, -112.15321542322636, -32.0]\t| 100AvgReward: [-100.0, -90.57624857909977, -19.2]\n",
      "19:21:27\tEpisode\t6\ttimesteps:\t99\tTook\t0.27234 sec - reward:\t[-100.0, -114.49040330201387, -24.0]\t| 100AvgReward: [-100.0, -94.5619410329188, -20.0]\n",
      "19:21:27\tEpisode\t7\ttimesteps:\t117\tTook\t0.330253 sec - reward:\t[-100.0, -233.35951027832925, -27.0]\t| 100AvgReward: [-100.0, -114.39016521083457, -21.0]\n",
      "19:21:27\tEpisode\t8\ttimesteps:\t96\tTook\t0.243059 sec - reward:\t[-100.0, -384.08598079904914, -33.0]\t| 100AvgReward: [-100.0, -148.1021421593614, -22.5]\n",
      "19:21:28\tEpisode\t9\ttimesteps:\t103\tTook\t0.303171 sec - reward:\t[-100.0, -145.31351410225034, -30.0]\t| 100AvgReward: [-100.0, -147.79229459746017, -23.333333333333332]\n",
      "19:21:28\tEpisode\t10\ttimesteps:\t90\tTook\t0.238192 sec - reward:\t[-100.0, 54.66622504591942, -23.0]\t| 100AvgReward: [-100.0, -127.54644263312221, -23.3]\n",
      "19:21:28\tEpisode\t11\ttimesteps:\t69\tTook\t0.212032 sec - reward:\t[-100.0, 96.50035440492866, -18.0]\t| 100AvgReward: [-100.0, -107.1785519932994, -22.818181818181817]\n",
      "19:21:28\tEpisode\t12\ttimesteps:\t78\tTook\t0.203109 sec - reward:\t[-100.0, -58.7399334218353, -19.0]\t| 100AvgReward: [-100.0, -103.1420004456774, -22.5]\n",
      "19:21:29\tEpisode\t13\ttimesteps:\t86\tTook\t0.269298 sec - reward:\t[-100.0, 99.33082784712315, -17.0]\t| 100AvgReward: [-100.0, -87.56716750007735, -22.076923076923077]\n",
      "19:21:29\tEpisode\t14\ttimesteps:\t131\tTook\t0.328797 sec - reward:\t[-100.0, 34.563376291655004, -36.0]\t| 100AvgReward: [-100.0, -78.84355722923932, -23.071428571428573]\n",
      "19:21:29\tEpisode\t15\ttimesteps:\t90\tTook\t0.25038 sec - reward:\t[-100.0, -44.951136671938, -22.0]\t| 100AvgReward: [-100.0, -76.58406252541924, -23.0]\n",
      "19:21:30\tEpisode\t16\ttimesteps:\t88\tTook\t0.266606 sec - reward:\t[-100.0, -185.18275979161263, -23.0]\t| 100AvgReward: [-100.0, -83.37148110455632, -23.0]\n",
      "19:21:30\tEpisode\t17\ttimesteps:\t67\tTook\t0.202195 sec - reward:\t[-100.0, 93.1302228718996, -18.0]\t| 100AvgReward: [-100.0, -72.98902792947068, -22.705882352941178]\n",
      "19:21:30\tEpisode\t18\ttimesteps:\t134\tTook\t0.332671 sec - reward:\t[-100.0, -255.5677059162408, -34.0]\t| 100AvgReward: [-100.0, -83.13228781762457, -23.333333333333332]\n",
      "19:21:30\tEpisode\t19\ttimesteps:\t64\tTook\t0.215162 sec - reward:\t[-100.0, -67.44293100386858, -21.0]\t| 100AvgReward: [-100.0, -82.30653219584795, -23.210526315789473]\n",
      "19:21:31\tEpisode\t20\ttimesteps:\t84\tTook\t0.248514 sec - reward:\t[-100.0, 127.42500247061253, -16.0]\t| 100AvgReward: [-100.0, -71.81995546252492, -22.85]\n",
      "19:21:31\tEpisode\t21\ttimesteps:\t94\tTook\t0.259463 sec - reward:\t[-100.0, -261.9705634340644, -24.0]\t| 100AvgReward: [-100.0, -80.87474631831252, -22.904761904761905]\n",
      "19:21:31\tEpisode\t22\ttimesteps:\t83\tTook\t0.241939 sec - reward:\t[-100.0, 71.78212507069111, -15.0]\t| 100AvgReward: [-100.0, -73.93579761881234, -22.545454545454547]\n",
      "19:21:31\tEpisode\t23\ttimesteps:\t72\tTook\t0.213053 sec - reward:\t[-100.0, 107.20304925739765, -17.0]\t| 100AvgReward: [-100.0, -66.06019558071627, -22.304347826086957]\n",
      "19:21:31\tEpisode\t24\ttimesteps:\t96\tTook\t0.248078 sec - reward:\t[-100.0, 125.99403790384531, -25.0]\t| 100AvgReward: [-100.0, -58.05793585219286, -22.416666666666668]\n",
      "19:21:32\tEpisode\t25\ttimesteps:\t102\tTook\t0.301578 sec - reward:\t[-100.0, 128.36097260937095, -24.0]\t| 100AvgReward: [-100.0, -50.601179513730315, -22.48]\n",
      "19:21:32\tEpisode\t26\ttimesteps:\t125\tTook\t0.316953 sec - reward:\t[-100.0, -204.2272468879819, -39.0]\t| 100AvgReward: [-100.0, -56.50987441273999, -23.115384615384617]\n",
      "19:21:32\tEpisode\t27\ttimesteps:\t98\tTook\t0.267113 sec - reward:\t[-100.0, 50.878213942050934, -29.0]\t| 100AvgReward: [-100.0, -52.53253780700699, -23.333333333333332]\n",
      "19:21:33\tEpisode\t28\ttimesteps:\t99\tTook\t0.294831 sec - reward:\t[-100.0, -339.9066333472729, -26.0]\t| 100AvgReward: [-100.0, -62.79589836201649, -23.428571428571427]\n",
      "19:21:33\tEpisode\t29\ttimesteps:\t128\tTook\t0.330224 sec - reward:\t[-100.0, -294.1606004163623, -35.0]\t| 100AvgReward: [-100.0, -70.77399153630428, -23.82758620689655]\n",
      "19:21:33\tEpisode\t30\ttimesteps:\t108\tTook\t0.309498 sec - reward:\t[-100.0, 53.901371620595455, -31.0]\t| 100AvgReward: [-100.0, -66.61814609774095, -24.066666666666666]\n",
      "19:21:34\tEpisode\t31\ttimesteps:\t78\tTook\t0.206604 sec - reward:\t[-100.0, 151.96309877187014, -14.0]\t| 100AvgReward: [-100.0, -59.56713819872124, -23.741935483870968]\n",
      "19:21:34\tEpisode\t32\ttimesteps:\t107\tTook\t0.297743 sec - reward:\t[-100.0, -117.99406275898218, -23.0]\t| 100AvgReward: [-100.0, -61.39297959122939, -23.71875]\n",
      "19:21:34\tEpisode\t33\ttimesteps:\t62\tTook\t0.183162 sec - reward:\t[-100.0, 20.407681845128536, -18.0]\t| 100AvgReward: [-100.0, -58.914171668915515, -23.545454545454547]\n",
      "19:21:34\tEpisode\t34\ttimesteps:\t100\tTook\t0.305992 sec - reward:\t[-100.0, -127.89579477906227, -31.0]\t| 100AvgReward: [-100.0, -60.943042936861005, -23.764705882352942]\n",
      "19:21:35\tEpisode\t35\ttimesteps:\t106\tTook\t0.272361 sec - reward:\t[-100.0, 68.45882776752114, -27.0]\t| 100AvgReward: [-100.0, -57.245846631021514, -23.857142857142858]\n",
      "19:21:35\tEpisode\t36\ttimesteps:\t101\tTook\t0.281072 sec - reward:\t[-100.0, -10.837852823548019, -23.0]\t| 100AvgReward: [-100.0, -55.95673569192503, -23.833333333333332]\n",
      "19:21:35\tEpisode\t37\ttimesteps:\t96\tTook\t0.27725 sec - reward:\t[-100.0, 96.34551879391074, -30.0]\t| 100AvgReward: [-100.0, -51.8404585436592, -24.0]\n",
      "19:21:35\tEpisode\t38\ttimesteps:\t61\tTook\t0.187498 sec - reward:\t[-100.0, 25.144347921013832, -7.0]\t| 100AvgReward: [-100.0, -49.81454258406254, -23.55263157894737]\n",
      "19:21:36\tEpisode\t39\ttimesteps:\t106\tTook\t0.282081 sec - reward:\t[-100.0, -120.56211699172854, -29.0]\t| 100AvgReward: [-100.0, -51.628582953489875, -23.692307692307693]\n",
      "19:21:36\tEpisode\t40\ttimesteps:\t76\tTook\t0.23434 sec - reward:\t[-100.0, 49.51376450061798, -14.0]\t| 100AvgReward: [-100.0, -49.10002426713718, -23.45]\n",
      "19:21:36\tEpisode\t41\ttimesteps:\t118\tTook\t0.329327 sec - reward:\t[-100.0, -472.75871481746435, -30.0]\t| 100AvgReward: [-100.0, -59.433163061047594, -23.609756097560975]\n",
      "19:21:36\tEpisode\t42\ttimesteps:\t85\tTook\t0.228477 sec - reward:\t[-100.0, -397.6966504752636, -36.0]\t| 100AvgReward: [-100.0, -67.48705561852893, -23.904761904761905]\n",
      "19:21:37\tEpisode\t43\ttimesteps:\t103\tTook\t0.300588 sec - reward:\t[-100.0, -241.97772884368896, -38.0]\t| 100AvgReward: [-100.0, -71.54497825167219, -24.232558139534884]\n",
      "19:21:37\tEpisode\t44\ttimesteps:\t73\tTook\t0.214784 sec - reward:\t[-100.0, -86.70544122904539, -14.0]\t| 100AvgReward: [-100.0, -71.88953422843066, -24.0]\n",
      "19:21:37\tEpisode\t45\ttimesteps:\t93\tTook\t0.249493 sec - reward:\t[-100.0, -95.8625020198524, -23.0]\t| 100AvgReward: [-100.0, -72.42226684601782, -23.977777777777778]\n",
      "19:21:37\tEpisode\t46\ttimesteps:\t113\tTook\t0.31499 sec - reward:\t[-100.0, -183.08040084131062, -33.0]\t| 100AvgReward: [-100.0, -74.82787845461114, -24.17391304347826]\n",
      "19:21:38\tEpisode\t47\ttimesteps:\t93\tTook\t0.266786 sec - reward:\t[-100.0, -335.18201187253, -35.0]\t| 100AvgReward: [-100.0, -80.36732810180091, -24.404255319148938]\n",
      "19:21:38\tEpisode\t48\ttimesteps:\t95\tTook\t0.260982 sec - reward:\t[-100.0, 49.480075001716614, -33.0]\t| 100AvgReward: [-100.0, -77.66217387047762, -24.583333333333332]\n",
      "19:21:38\tEpisode\t49\ttimesteps:\t92\tTook\t0.271056 sec - reward:\t[-100.0, -210.2660907034442, -30.0]\t| 100AvgReward: [-100.0, -80.36837625482387, -24.693877551020407]\n",
      "19:21:38\tEpisode\t50\ttimesteps:\t70\tTook\t0.206469 sec - reward:\t[-100.0, 67.47724549472332, -13.0]\t| 100AvgReward: [-100.0, -77.41146381983293, -24.46]\n",
      "19:21:39\tEpisode\t51\ttimesteps:\t139\tTook\t0.359278 sec - reward:\t[-100.0, -146.21991249523126, -43.0]\t| 100AvgReward: [-100.0, -78.760649087978, -24.823529411764707]\n",
      "19:21:39\tEpisode\t52\ttimesteps:\t103\tTook\t0.304022 sec - reward:\t[-100.0, 60.4434142105747, -34.0]\t| 100AvgReward: [-100.0, -76.08364787069814, -25.0]\n",
      "19:21:39\tEpisode\t53\ttimesteps:\t82\tTook\t0.216845 sec - reward:\t[-100.0, -117.79509577155113, -23.0]\t| 100AvgReward: [-100.0, -76.87065632165763, -24.962264150943398]\n",
      "19:21:40\tEpisode\t54\ttimesteps:\t77\tTook\t0.226963 sec - reward:\t[-100.0, 61.513635858893394, -17.0]\t| 100AvgReward: [-100.0, -74.30798424424002, -24.814814814814813]\n",
      "19:21:40\tEpisode\t55\ttimesteps:\t102\tTook\t0.30659 sec - reward:\t[-100.0, 45.1690164366737, -31.0]\t| 100AvgReward: [-100.0, -72.13567514095068, -24.927272727272726]\n",
      "19:21:40\tEpisode\t56\ttimesteps:\t90\tTook\t0.267974 sec - reward:\t[-100.0, -191.15886600129306, -39.0]\t| 100AvgReward: [-100.0, -74.2610892634568, -25.178571428571427]\n",
      "19:21:41\tEpisode\t57\ttimesteps:\t163\tTook\t0.447738 sec - reward:\t[-100.0, 14.514820780139416, -69.0]\t| 100AvgReward: [-100.0, -72.7036171574288, -25.94736842105263]\n",
      "19:21:41\tEpisode\t58\ttimesteps:\t69\tTook\t0.216724 sec - reward:\t[-100.0, 193.0270747197792, -24.0]\t| 100AvgReward: [-100.0, -68.12205350437348, -25.913793103448278]\n",
      "19:21:41\tEpisode\t59\ttimesteps:\t107\tTook\t0.268791 sec - reward:\t[-100.0, 19.790946973487735, -21.0]\t| 100AvgReward: [-100.0, -66.63200264881651, -25.83050847457627]\n",
      "19:21:41\tEpisode\t60\ttimesteps:\t105\tTook\t0.313194 sec - reward:\t[-100.0, -163.41582444077358, -24.0]\t| 100AvgReward: [-100.0, -68.24506634534913, -25.8]\n",
      "19:21:42\tEpisode\t61\ttimesteps:\t68\tTook\t0.210629 sec - reward:\t[-100.0, 52.41617417708039, -13.0]\t| 100AvgReward: [-100.0, -66.26701322203061, -25.59016393442623]\n",
      "19:21:42\tEpisode\t62\ttimesteps:\t125\tTook\t0.333035 sec - reward:\t[-100.0, -369.38372586481273, -39.0]\t| 100AvgReward: [-100.0, -71.15599245820451, -25.806451612903224]\n",
      "19:21:42\tEpisode\t63\ttimesteps:\t96\tTook\t0.287298 sec - reward:\t[-100.0, -140.70147543400526, -22.0]\t| 100AvgReward: [-100.0, -72.25988901337595, -25.746031746031747]\n",
      "19:21:43\tEpisode\t64\ttimesteps:\t159\tTook\t0.418486 sec - reward:\t[-100.0, 49.38135704305023, -74.0]\t| 100AvgReward: [-100.0, -70.3592445437443, -26.5]\n",
      "19:21:43\tEpisode\t65\ttimesteps:\t66\tTook\t0.192828 sec - reward:\t[-100.0, -39.892097532749176, -8.0]\t| 100AvgReward: [-100.0, -69.8905192051136, -26.215384615384615]\n",
      "19:21:43\tEpisode\t66\ttimesteps:\t77\tTook\t0.232199 sec - reward:\t[-100.0, -245.07424497790635, -13.0]\t| 100AvgReward: [-100.0, -72.54481808045895, -26.015151515151516]\n",
      "19:21:43\tEpisode\t67\ttimesteps:\t86\tTook\t0.240906 sec - reward:\t[-100.0, -139.31889636954293, -17.0]\t| 100AvgReward: [-100.0, -73.54144611462438, -25.880597014925375]\n",
      "19:21:44\tEpisode\t68\ttimesteps:\t85\tTook\t0.234382 sec - reward:\t[-100.0, 9.099635859951377, -19.0]\t| 100AvgReward: [-100.0, -72.3261360855865, -25.779411764705884]\n",
      "19:21:44\tEpisode\t69\ttimesteps:\t78\tTook\t0.259963 sec - reward:\t[-100.0, -279.2833294272423, -19.0]\t| 100AvgReward: [-100.0, -75.32551569923369, -25.681159420289855]\n",
      "19:21:44\tEpisode\t70\ttimesteps:\t68\tTook\t0.189628 sec - reward:\t[-100.0, 68.46184923872352, -11.0]\t| 100AvgReward: [-100.0, -73.2714104858343, -25.47142857142857]\n",
      "19:21:44\tEpisode\t71\ttimesteps:\t66\tTook\t0.208604 sec - reward:\t[-100.0, 28.891448974609375, -15.0]\t| 100AvgReward: [-100.0, -71.83249697230693, -25.323943661971832]\n",
      "19:21:44\tEpisode\t72\ttimesteps:\t70\tTook\t0.208893 sec - reward:\t[-100.0, -83.24511583149433, -29.0]\t| 100AvgReward: [-100.0, -71.99100556757341, -25.375]\n",
      "19:21:45\tEpisode\t73\ttimesteps:\t100\tTook\t0.299018 sec - reward:\t[-100.0, -391.3289162963629, -39.0]\t| 100AvgReward: [-100.0, -76.36549749536505, -25.561643835616437]\n",
      "19:21:45\tEpisode\t74\ttimesteps:\t96\tTook\t0.261025 sec - reward:\t[-100.0, -282.3241858892143, -16.0]\t| 100AvgReward: [-100.0, -79.14872301420085, -25.43243243243243]\n",
      "19:21:45\tEpisode\t75\ttimesteps:\t59\tTook\t0.175084 sec - reward:\t[-100.0, 0.08735097944736481, -14.0]\t| 100AvgReward: [-100.0, -78.09224202761888, -25.28]\n",
      "19:21:45\tEpisode\t76\ttimesteps:\t109\tTook\t0.327425 sec - reward:\t[-100.0, 49.77294394024648, -15.0]\t| 100AvgReward: [-100.0, -76.40980537014696, -25.144736842105264]\n",
      "19:21:46\tEpisode\t77\ttimesteps:\t87\tTook\t0.253898 sec - reward:\t[-100.0, -401.8708643242717, -38.0]\t| 100AvgReward: [-100.0, -80.63657236955117, -25.31168831168831]\n",
      "19:21:46\tEpisode\t78\ttimesteps:\t99\tTook\t0.289455 sec - reward:\t[-100.0, -241.8120515558403, -50.0]\t| 100AvgReward: [-100.0, -82.7029246668113, -25.628205128205128]\n",
      "19:21:46\tEpisode\t79\ttimesteps:\t79\tTook\t0.249599 sec - reward:\t[-100.0, -157.43573232740164, -22.0]\t| 100AvgReward: [-100.0, -83.64890957390737, -25.582278481012658]\n",
      "19:21:47\tEpisode\t80\ttimesteps:\t76\tTook\t0.21893 sec - reward:\t[-100.0, -247.37876558676362, -23.0]\t| 100AvgReward: [-100.0, -85.69553277406808, -25.55]\n",
      "19:21:47\tEpisode\t81\ttimesteps:\t59\tTook\t0.1875 sec - reward:\t[-100.0, 172.7426116578281, -11.0]\t| 100AvgReward: [-100.0, -82.50493839836565, -25.37037037037037]\n",
      "19:21:47\tEpisode\t82\ttimesteps:\t79\tTook\t0.251549 sec - reward:\t[-100.0, -255.68964295182377, -32.0]\t| 100AvgReward: [-100.0, -84.616946990481, -25.451219512195124]\n",
      "19:21:47\tEpisode\t83\ttimesteps:\t92\tTook\t0.265623 sec - reward:\t[-100.0, 42.17487161466852, -20.0]\t| 100AvgReward: [-100.0, -83.0893347181298, -25.3855421686747]\n",
      "19:21:47\tEpisode\t84\ttimesteps:\t88\tTook\t0.256752 sec - reward:\t[-100.0, -72.91430528461933, -14.0]\t| 100AvgReward: [-100.0, -82.96820341534992, -25.25]\n",
      "19:21:48\tEpisode\t85\ttimesteps:\t82\tTook\t0.253046 sec - reward:\t[-100.0, 18.682460493873805, -23.0]\t| 100AvgReward: [-100.0, -81.77231325171199, -25.223529411764705]\n",
      "19:21:48\tEpisode\t86\ttimesteps:\t66\tTook\t0.21402 sec - reward:\t[-100.0, -281.7102130651474, -9.0]\t| 100AvgReward: [-100.0, -84.09717255186821, -25.03488372093023]\n",
      "19:21:48\tEpisode\t87\ttimesteps:\t60\tTook\t0.183317 sec - reward:\t[-100.0, 179.90379533171654, -7.0]\t| 100AvgReward: [-100.0, -81.06267866814885, -24.82758620689655]\n",
      "19:21:48\tEpisode\t88\ttimesteps:\t66\tTook\t0.199045 sec - reward:\t[-100.0, 60.06171188503504, -12.0]\t| 100AvgReward: [-100.0, -79.45899241186267, -24.681818181818183]\n",
      "19:21:49\tEpisode\t89\ttimesteps:\t98\tTook\t0.291266 sec - reward:\t[-100.0, 57.537628813646734, -21.0]\t| 100AvgReward: [-100.0, -77.91970453292436, -24.640449438202246]\n",
      "19:21:49\tEpisode\t90\ttimesteps:\t77\tTook\t0.207663 sec - reward:\t[-100.0, 40.86420247144997, -14.0]\t| 100AvgReward: [-100.0, -76.59988334398687, -24.522222222222222]\n",
      "19:21:49\tEpisode\t91\ttimesteps:\t137\tTook\t0.373544 sec - reward:\t[-100.0, -476.7979601956904, -75.0]\t| 100AvgReward: [-100.0, -80.9976644082913, -25.076923076923077]\n",
      "19:21:49\tEpisode\t92\ttimesteps:\t74\tTook\t0.224856 sec - reward:\t[-100.0, -271.0081088989973, -17.0]\t| 100AvgReward: [-100.0, -83.06299532666854, -24.98913043478261]\n",
      "19:21:50\tEpisode\t93\ttimesteps:\t64\tTook\t0.204774 sec - reward:\t[-100.0, -210.96353502757847, -17.0]\t| 100AvgReward: [-100.0, -84.43826994710844, -24.903225806451612]\n",
      "19:21:50\tEpisode\t94\ttimesteps:\t92\tTook\t0.250484 sec - reward:\t[-100.0, -48.64874705672264, -15.0]\t| 100AvgReward: [-100.0, -84.05753034189156, -24.79787234042553]\n",
      "19:21:50\tEpisode\t95\ttimesteps:\t93\tTook\t0.296724 sec - reward:\t[-100.0, -188.2977957725525, -17.0]\t| 100AvgReward: [-100.0, -85.15479629379325, -24.71578947368421]\n",
      "19:21:50\tEpisode\t96\ttimesteps:\t96\tTook\t0.269296 sec - reward:\t[-100.0, -202.47149155521765, -10.0]\t| 100AvgReward: [-100.0, -86.37684520276643, -24.5625]\n",
      "19:21:51\tEpisode\t97\ttimesteps:\t115\tTook\t0.332735 sec - reward:\t[-100.0, -244.97820579633117, -63.0]\t| 100AvgReward: [-100.0, -88.01191077589596, -24.95876288659794]\n",
      "19:21:51\tEpisode\t98\ttimesteps:\t58\tTook\t0.214912 sec - reward:\t[-100.0, -13.517777487635612, -9.0]\t| 100AvgReward: [-100.0, -87.25176655866882, -24.79591836734694]\n",
      "19:21:51\tEpisode\t99\ttimesteps:\t91\tTook\t0.280344 sec - reward:\t[-100.0, -235.38927068933845, -11.0]\t| 100AvgReward: [-100.0, -88.74810498423113, -24.656565656565657]\n",
      "19:21:52\tEpisode\t100\ttimesteps:\t81\tTook\t0.235323 sec - reward:\t[-100.0, -60.261217817664146, -10.0]\t| 100AvgReward: [-100.0, -88.46323611256547, -24.51]\n",
      "19:21:52\tEpisode\t101\ttimesteps:\t66\tTook\t0.219397 sec - reward:\t[-100.0, -53.99197790026665, -18.0]\t| 100AvgReward: [-100.0, -87.60042451408572, -24.49]\n",
      "19:21:52\tEpisode\t102\ttimesteps:\t86\tTook\t0.251816 sec - reward:\t[-100.0, -288.0512532815337, -26.0]\t| 100AvgReward: [-100.0, -88.5625823462463, -24.54]\n",
      "19:21:53\tEpisode\t103\ttimesteps:\t220\tTook\t0.576033 sec - reward:\t[-100.0, -248.26538674347103, -113.0]\t| 100AvgReward: [-100.0, -91.04858190531722, -25.58]\n",
      "19:21:53\tEpisode\t104\ttimesteps:\t92\tTook\t0.286431 sec - reward:\t[-100.0, -239.95178544521332, -16.0]\t| 100AvgReward: [-100.0, -93.35855987154758, -25.6]\n",
      "19:21:53\tEpisode\t105\ttimesteps:\t96\tTook\t0.278819 sec - reward:\t[-100.0, -388.5540029704571, -38.0]\t| 100AvgReward: [-100.0, -96.1225677470199, -25.66]\n",
      "19:21:53\tEpisode\t106\ttimesteps:\t56\tTook\t0.180301 sec - reward:\t[-100.0, -2.105401560664177, -11.0]\t| 100AvgReward: [-100.0, -94.9987177296064, -25.53]\n",
      "19:21:54\tEpisode\t107\ttimesteps:\t85\tTook\t0.259119 sec - reward:\t[-100.0, -377.7325519621372, -22.0]\t| 100AvgReward: [-100.0, -96.44244814644448, -25.48]\n",
      "19:21:54\tEpisode\t108\ttimesteps:\t82\tTook\t0.233945 sec - reward:\t[-100.0, -66.55877901613712, -19.0]\t| 100AvgReward: [-100.0, -93.26717612861536, -25.34]\n",
      "19:21:54\tEpisode\t109\ttimesteps:\t77\tTook\t0.236577 sec - reward:\t[-100.0, -334.9219210445881, -11.0]\t| 100AvgReward: [-100.0, -95.16326019803873, -25.15]\n",
      "19:21:54\tEpisode\t110\ttimesteps:\t113\tTook\t0.326689 sec - reward:\t[-100.0, -211.26491896249354, -59.0]\t| 100AvgReward: [-100.0, -97.82257163812287, -25.51]\n",
      "19:21:55\tEpisode\t111\ttimesteps:\t90\tTook\t0.257546 sec - reward:\t[-100.0, -419.5395192615688, -15.0]\t| 100AvgReward: [-100.0, -102.98297037478784, -25.48]\n",
      "19:21:55\tEpisode\t112\ttimesteps:\t58\tTook\t0.175654 sec - reward:\t[-100.0, 47.792494219727814, -8.0]\t| 100AvgReward: [-100.0, -101.9176460983722, -25.37]\n",
      "19:21:55\tEpisode\t113\ttimesteps:\t91\tTook\t0.287658 sec - reward:\t[-100.0, 74.22949685156345, -14.0]\t| 100AvgReward: [-100.0, -102.1686594083278, -25.34]\n",
      "19:21:55\tEpisode\t114\ttimesteps:\t98\tTook\t0.261329 sec - reward:\t[-100.0, -307.00048016011715, -15.0]\t| 100AvgReward: [-100.0, -105.58429797284552, -25.13]\n",
      "19:21:56\tEpisode\t115\ttimesteps:\t159\tTook\t0.427646 sec - reward:\t[-100.0, -440.57224276661873, -75.0]\t| 100AvgReward: [-100.0, -109.54050903379233, -25.66]\n",
      "19:21:56\tEpisode\t116\ttimesteps:\t67\tTook\t0.216034 sec - reward:\t[-100.0, -126.00382475554943, -9.0]\t| 100AvgReward: [-100.0, -108.9487196834317, -25.52]\n",
      "19:21:56\tEpisode\t117\ttimesteps:\t186\tTook\t0.47945 sec - reward:\t[-100.0, -328.62280868925154, -83.0]\t| 100AvgReward: [-100.0, -113.16624999904322, -26.17]\n",
      "19:21:57\tEpisode\t118\ttimesteps:\t77\tTook\t0.244021 sec - reward:\t[-100.0, -55.70640414953232, -10.0]\t| 100AvgReward: [-100.0, -111.16763698137612, -25.93]\n",
      "19:21:57\tEpisode\t119\ttimesteps:\t64\tTook\t0.19333 sec - reward:\t[-100.0, -137.92581118643284, -10.0]\t| 100AvgReward: [-100.0, -111.87246578320178, -25.82]\n",
      "19:21:57\tEpisode\t120\ttimesteps:\t71\tTook\t0.208016 sec - reward:\t[-100.0, -80.70401367545128, -11.0]\t| 100AvgReward: [-100.0, -113.9537559446624, -25.77]\n",
      "19:21:57\tEpisode\t121\ttimesteps:\t70\tTook\t0.197366 sec - reward:\t[-100.0, -171.56804603338242, -14.0]\t| 100AvgReward: [-100.0, -113.04973077065559, -25.67]\n",
      "19:21:58\tEpisode\t122\ttimesteps:\t67\tTook\t0.228228 sec - reward:\t[-100.0, -34.20572376251221, -5.0]\t| 100AvgReward: [-100.0, -114.10960925898762, -25.57]\n",
      "19:21:58\tEpisode\t123\ttimesteps:\t70\tTook\t0.205272 sec - reward:\t[-100.0, 133.70735692605376, -7.0]\t| 100AvgReward: [-100.0, -113.84456618230107, -25.47]\n",
      "19:21:58\tEpisode\t124\ttimesteps:\t92\tTook\t0.257314 sec - reward:\t[-100.0, -335.3711036220193, -6.0]\t| 100AvgReward: [-100.0, -118.45821759755971, -25.28]\n",
      "19:21:59\tEpisode\t125\ttimesteps:\t211\tTook\t0.580601 sec - reward:\t[-100.0, -483.5180865121074, -122.0]\t| 100AvgReward: [-100.0, -124.57700818877449, -26.26]\n",
      "19:21:59\tEpisode\t126\ttimesteps:\t50\tTook\t0.148144 sec - reward:\t[-100.0, 47.25825494714081, -4.0]\t| 100AvgReward: [-100.0, -122.06215317042326, -25.91]\n",
      "19:21:59\tEpisode\t127\ttimesteps:\t56\tTook\t0.176661 sec - reward:\t[-100.0, -12.763273108750582, -4.0]\t| 100AvgReward: [-100.0, -122.69856804093128, -25.66]\n",
      "19:21:59\tEpisode\t128\ttimesteps:\t66\tTook\t0.211028 sec - reward:\t[-100.0, -280.30360665917397, -14.0]\t| 100AvgReward: [-100.0, -122.10253777405029, -25.54]\n",
      "19:21:59\tEpisode\t129\ttimesteps:\t61\tTook\t0.193691 sec - reward:\t[-100.0, -128.3165329322219, -10.0]\t| 100AvgReward: [-100.0, -120.44409709920889, -25.29]\n",
      "19:22:00\tEpisode\t130\ttimesteps:\t85\tTook\t0.257044 sec - reward:\t[-100.0, -49.61566749587655, -8.0]\t| 100AvgReward: [-100.0, -121.4792674903736, -25.06]\n",
      "19:22:00\tEpisode\t131\ttimesteps:\t91\tTook\t0.274206 sec - reward:\t[-100.0, -189.6930357720703, -56.0]\t| 100AvgReward: [-100.0, -124.895828835813, -25.48]\n",
      "19:22:00\tEpisode\t132\ttimesteps:\t66\tTook\t0.198657 sec - reward:\t[-100.0, -163.45607795007527, -13.0]\t| 100AvgReward: [-100.0, -125.35044898772394, -25.38]\n",
      "19:22:00\tEpisode\t133\ttimesteps:\t89\tTook\t0.261865 sec - reward:\t[-100.0, -330.9181065749144, -55.0]\t| 100AvgReward: [-100.0, -128.86370687192436, -25.75]\n",
      "19:22:00\tEpisode\t134\ttimesteps:\t58\tTook\t0.171831 sec - reward:\t[-100.0, -139.872979298234, -6.0]\t| 100AvgReward: [-100.0, -128.9834787171161, -25.5]\n",
      "19:22:01\tEpisode\t135\ttimesteps:\t95\tTook\t0.301426 sec - reward:\t[-100.0, -140.5582797769457, -68.0]\t| 100AvgReward: [-100.0, -131.07364979256076, -25.91]\n",
      "19:22:01\tEpisode\t136\ttimesteps:\t83\tTook\t0.23423 sec - reward:\t[-100.0, -168.24605572479777, -13.0]\t| 100AvgReward: [-100.0, -132.64773182157325, -25.81]\n",
      "19:22:01\tEpisode\t137\ttimesteps:\t73\tTook\t0.21527 sec - reward:\t[-100.0, 89.18512971699238, -6.0]\t| 100AvgReward: [-100.0, -132.71933571234243, -25.57]\n",
      "19:22:01\tEpisode\t138\ttimesteps:\t75\tTook\t0.234385 sec - reward:\t[-100.0, -240.32122588157654, -12.0]\t| 100AvgReward: [-100.0, -135.37399145036835, -25.62]\n",
      "19:22:02\tEpisode\t139\ttimesteps:\t60\tTook\t0.195498 sec - reward:\t[-100.0, -29.862423792481422, -6.0]\t| 100AvgReward: [-100.0, -134.46699451837586, -25.39]\n",
      "19:22:02\tEpisode\t140\ttimesteps:\t79\tTook\t0.235965 sec - reward:\t[-100.0, -232.0339457578957, -8.0]\t| 100AvgReward: [-100.0, -137.28247162096102, -25.33]\n",
      "19:22:02\tEpisode\t141\ttimesteps:\t105\tTook\t0.315388 sec - reward:\t[-100.0, -401.07572578266263, -71.0]\t| 100AvgReward: [-100.0, -136.56564173061298, -25.74]\n",
      "19:22:02\tEpisode\t142\ttimesteps:\t64\tTook\t0.187288 sec - reward:\t[-100.0, 68.70365112577565, -11.0]\t| 100AvgReward: [-100.0, -131.9016387146026, -25.49]\n",
      "19:22:03\tEpisode\t143\ttimesteps:\t57\tTook\t0.192353 sec - reward:\t[-100.0, 105.7704666852951, -7.0]\t| 100AvgReward: [-100.0, -128.42415675931275, -25.18]\n",
      "19:22:03\tEpisode\t144\ttimesteps:\t64\tTook\t0.204391 sec - reward:\t[-100.0, -138.94418001174927, -8.0]\t| 100AvgReward: [-100.0, -128.9465441471398, -25.12]\n",
      "19:22:03\tEpisode\t145\ttimesteps:\t71\tTook\t0.222096 sec - reward:\t[-100.0, 156.46871568448842, -4.0]\t| 100AvgReward: [-100.0, -126.42323197009638, -24.93]\n",
      "19:22:03\tEpisode\t146\ttimesteps:\t92\tTook\t0.276386 sec - reward:\t[-100.0, -341.1682279706001, -7.0]\t| 100AvgReward: [-100.0, -128.00411024138927, -24.67]\n",
      "19:22:04\tEpisode\t147\ttimesteps:\t122\tTook\t0.336413 sec - reward:\t[-100.0, -750.6292523518205, -32.0]\t| 100AvgReward: [-100.0, -132.1585826461822, -24.64]\n",
      "19:22:04\tEpisode\t148\ttimesteps:\t118\tTook\t0.346214 sec - reward:\t[-100.0, -132.27867783792317, -79.0]\t| 100AvgReward: [-100.0, -133.97617017457858, -25.1]\n",
      "19:22:04\tEpisode\t149\ttimesteps:\t97\tTook\t0.276196 sec - reward:\t[-100.0, -208.9990432932973, -22.0]\t| 100AvgReward: [-100.0, -133.96349970047712, -25.02]\n",
      "19:22:04\tEpisode\t150\ttimesteps:\t83\tTook\t0.240161 sec - reward:\t[-100.0, -190.11599200963974, -13.0]\t| 100AvgReward: [-100.0, -136.53943207552075, -25.02]\n",
      "19:22:05\tEpisode\t151\ttimesteps:\t62\tTook\t0.211274 sec - reward:\t[-100.0, -139.5906729400158, -10.0]\t| 100AvgReward: [-100.0, -136.4731396799686, -24.69]\n",
      "19:22:05\tEpisode\t152\ttimesteps:\t124\tTook\t0.32936 sec - reward:\t[-100.0, -393.67341540474445, -51.0]\t| 100AvgReward: [-100.0, -141.01430797612178, -24.86]\n",
      "19:22:05\tEpisode\t153\ttimesteps:\t104\tTook\t0.298955 sec - reward:\t[-100.0, -362.79774801433086, -36.0]\t| 100AvgReward: [-100.0, -143.4643344985496, -24.99]\n",
      "19:22:06\tEpisode\t154\ttimesteps:\t90\tTook\t0.264245 sec - reward:\t[-100.0, -66.66971915960312, -32.0]\t| 100AvgReward: [-100.0, -144.74616804873455, -25.14]\n",
      "19:22:06\tEpisode\t155\ttimesteps:\t54\tTook\t0.176343 sec - reward:\t[-100.0, -65.68205428123474, -3.0]\t| 100AvgReward: [-100.0, -145.85467875591362, -24.86]\n",
      "19:22:06\tEpisode\t156\ttimesteps:\t67\tTook\t0.198232 sec - reward:\t[-100.0, -297.03496408089995, -6.0]\t| 100AvgReward: [-100.0, -146.9134397367097, -24.53]\n",
      "19:22:06\tEpisode\t157\ttimesteps:\t184\tTook\t0.503976 sec - reward:\t[-100.0, -587.3074850663543, -74.0]\t| 100AvgReward: [-100.0, -152.93166279517465, -24.58]\n",
      "19:22:07\tEpisode\t158\ttimesteps:\t72\tTook\t0.223276 sec - reward:\t[-100.0, -168.56457817554474, -11.0]\t| 100AvgReward: [-100.0, -156.54757932412787, -24.45]\n",
      "19:22:07\tEpisode\t159\ttimesteps:\t56\tTook\t0.182881 sec - reward:\t[-100.0, -33.01069324463606, -6.0]\t| 100AvgReward: [-100.0, -157.0755957263091, -24.3]\n",
      "19:22:07\tEpisode\t160\ttimesteps:\t68\tTook\t0.225046 sec - reward:\t[-100.0, -156.57001912593842, -11.0]\t| 100AvgReward: [-100.0, -157.00713767316077, -24.17]\n",
      "19:22:07\tEpisode\t161\ttimesteps:\t133\tTook\t0.37697 sec - reward:\t[-100.0, -260.15913590602577, -85.0]\t| 100AvgReward: [-100.0, -160.13289077399182, -24.89]\n",
      "19:22:08\tEpisode\t162\ttimesteps:\t195\tTook\t0.555116 sec - reward:\t[-100.0, -444.5140642635524, -126.0]\t| 100AvgReward: [-100.0, -160.8841941579792, -25.76]\n",
      "19:22:08\tEpisode\t163\ttimesteps:\t60\tTook\t0.193127 sec - reward:\t[-100.0, -403.4929656945169, -18.0]\t| 100AvgReward: [-100.0, -163.51210906058432, -25.72]\n",
      "19:22:08\tEpisode\t164\ttimesteps:\t56\tTook\t0.182763 sec - reward:\t[-100.0, -26.026337794959545, -8.0]\t| 100AvgReward: [-100.0, -164.26618600896444, -25.06]\n",
      "19:22:09\tEpisode\t165\ttimesteps:\t154\tTook\t0.450057 sec - reward:\t[-100.0, -578.1557384543121, -114.0]\t| 100AvgReward: [-100.0, -169.64882241818006, -26.12]\n",
      "19:22:09\tEpisode\t166\ttimesteps:\t65\tTook\t0.206137 sec - reward:\t[-100.0, -343.7223263680935, -16.0]\t| 100AvgReward: [-100.0, -170.63530323208192, -26.15]\n",
      "19:22:09\tEpisode\t167\ttimesteps:\t53\tTook\t0.16224 sec - reward:\t[-100.0, -37.653719544410706, -3.0]\t| 100AvgReward: [-100.0, -169.61865146383062, -26.01]\n",
      "19:22:09\tEpisode\t168\ttimesteps:\t64\tTook\t0.212064 sec - reward:\t[-100.0, -215.04642736911774, -7.0]\t| 100AvgReward: [-100.0, -171.8601120961213, -25.89]\n",
      "19:22:10\tEpisode\t169\ttimesteps:\t86\tTook\t0.273702 sec - reward:\t[-100.0, -250.40415400266647, -8.0]\t| 100AvgReward: [-100.0, -171.57132034187555, -25.78]\n",
      "19:22:10\tEpisode\t170\ttimesteps:\t196\tTook\t0.559891 sec - reward:\t[-100.0, -511.3243439607322, -132.0]\t| 100AvgReward: [-100.0, -177.3691822738701, -26.99]\n",
      "19:22:11\tEpisode\t171\ttimesteps:\t94\tTook\t0.288168 sec - reward:\t[-100.0, -274.4331622980535, -61.0]\t| 100AvgReward: [-100.0, -180.40242838659674, -27.45]\n",
      "19:22:11\tEpisode\t172\ttimesteps:\t90\tTook\t0.257903 sec - reward:\t[-100.0, -288.25045235455036, -51.0]\t| 100AvgReward: [-100.0, -182.4524817518273, -27.67]\n",
      "19:22:12\tEpisode\t173\ttimesteps:\t272\tTook\t0.758006 sec - reward:\t[-100.0, -1235.676527030766, -185.0]\t| 100AvgReward: [-100.0, -190.89595785917132, -29.13]\n",
      "19:22:12\tEpisode\t174\ttimesteps:\t59\tTook\t0.187485 sec - reward:\t[-100.0, 87.0180915016681, -3.0]\t| 100AvgReward: [-100.0, -187.2025350852625, -29.0]\n",
      "19:22:12\tEpisode\t175\ttimesteps:\t107\tTook\t0.299014 sec - reward:\t[-100.0, -566.2487525343895, -35.0]\t| 100AvgReward: [-100.0, -192.86589612040086, -29.21]\n",
      "19:22:13\tEpisode\t176\ttimesteps:\t249\tTook\t0.719993 sec - reward:\t[-100.0, -284.7577202534303, -101.0]\t| 100AvgReward: [-100.0, -196.21120276233762, -30.07]\n",
      "19:22:13\tEpisode\t177\ttimesteps:\t192\tTook\t0.528272 sec - reward:\t[-100.0, -769.2903098929673, -109.0]\t| 100AvgReward: [-100.0, -199.8853972180246, -30.78]\n",
      "19:22:14\tEpisode\t178\ttimesteps:\t66\tTook\t0.19976 sec - reward:\t[-100.0, -193.3531482219696, -4.0]\t| 100AvgReward: [-100.0, -199.40080818468587, -30.32]\n",
      "19:22:14\tEpisode\t179\ttimesteps:\t232\tTook\t0.632209 sec - reward:\t[-100.0, -620.8213092777878, -137.0]\t| 100AvgReward: [-100.0, -204.03466395418974, -31.47]\n",
      "19:22:14\tEpisode\t180\ttimesteps:\t57\tTook\t0.183766 sec - reward:\t[-100.0, -38.055355712771416, -5.0]\t| 100AvgReward: [-100.0, -201.94142985544983, -31.29]\n",
      "19:22:15\tEpisode\t181\ttimesteps:\t63\tTook\t0.199452 sec - reward:\t[-100.0, -277.3935894370079, -4.0]\t| 100AvgReward: [-100.0, -206.44279186639818, -31.22]\n",
      "19:22:15\tEpisode\t182\ttimesteps:\t51\tTook\t0.151867 sec - reward:\t[-100.0, 23.48526042699814, -2.0]\t| 100AvgReward: [-100.0, -203.65104283260996, -30.92]\n",
      "19:22:15\tEpisode\t183\ttimesteps:\t74\tTook\t0.243269 sec - reward:\t[-100.0, -147.58345293998718, -5.0]\t| 100AvgReward: [-100.0, -205.54862607815653, -30.77]\n",
      "19:22:15\tEpisode\t184\ttimesteps:\t72\tTook\t0.234454 sec - reward:\t[-100.0, -227.34725614637136, -2.0]\t| 100AvgReward: [-100.0, -207.09295558677405, -30.65]\n",
      "19:22:15\tEpisode\t185\ttimesteps:\t86\tTook\t0.243421 sec - reward:\t[-100.0, -209.87641890347004, -15.0]\t| 100AvgReward: [-100.0, -209.37854438074748, -30.57]\n",
      "19:22:16\tEpisode\t186\ttimesteps:\t105\tTook\t0.3202 sec - reward:\t[-100.0, -330.94821375608444, -50.0]\t| 100AvgReward: [-100.0, -209.87092438765686, -30.98]\n",
      "19:22:16\tEpisode\t187\ttimesteps:\t78\tTook\t0.242775 sec - reward:\t[-100.0, -437.2851474285126, -9.0]\t| 100AvgReward: [-100.0, -216.04281381525914, -31.0]\n",
      "19:22:16\tEpisode\t188\ttimesteps:\t90\tTook\t0.247074 sec - reward:\t[-100.0, -381.55800515413284, -34.0]\t| 100AvgReward: [-100.0, -220.45901098565082, -31.22]\n",
      "19:22:17\tEpisode\t189\ttimesteps:\t93\tTook\t0.30465 sec - reward:\t[-100.0, -278.64789430983365, -16.0]\t| 100AvgReward: [-100.0, -223.82086621688563, -31.17]\n",
      "19:22:17\tEpisode\t190\ttimesteps:\t82\tTook\t0.239703 sec - reward:\t[-100.0, -327.04880648851395, -6.0]\t| 100AvgReward: [-100.0, -227.49999630648526, -31.09]\n",
      "19:22:17\tEpisode\t191\ttimesteps:\t75\tTook\t0.223966 sec - reward:\t[-100.0, -332.60334023833275, -13.0]\t| 100AvgReward: [-100.0, -226.05805010691168, -30.47]\n",
      "19:22:17\tEpisode\t192\ttimesteps:\t60\tTook\t0.210572 sec - reward:\t[-100.0, -19.242676611989737, -10.0]\t| 100AvgReward: [-100.0, -223.5403957840416, -30.4]\n",
      "19:22:17\tEpisode\t193\ttimesteps:\t59\tTook\t0.187309 sec - reward:\t[-100.0, -26.36757457256317, -6.0]\t| 100AvgReward: [-100.0, -221.69443617949145, -30.29]\n",
      "19:22:18\tEpisode\t194\ttimesteps:\t71\tTook\t0.227878 sec - reward:\t[-100.0, -170.89905834943056, -4.0]\t| 100AvgReward: [-100.0, -222.91693929241853, -30.18]\n",
      "19:22:18\tEpisode\t195\ttimesteps:\t106\tTook\t0.292116 sec - reward:\t[-100.0, -270.93253763346, -76.0]\t| 100AvgReward: [-100.0, -223.74328671102762, -30.77]\n",
      "19:22:18\tEpisode\t196\ttimesteps:\t91\tTook\t0.288298 sec - reward:\t[-100.0, -344.70436415076256, -64.0]\t| 100AvgReward: [-100.0, -225.16561543698307, -31.31]\n",
      "19:22:18\tEpisode\t197\ttimesteps:\t79\tTook\t0.234373 sec - reward:\t[-100.0, -246.48105950653553, -60.0]\t| 100AvgReward: [-100.0, -225.18064397408511, -31.28]\n",
      "19:22:19\tEpisode\t198\ttimesteps:\t52\tTook\t0.174172 sec - reward:\t[-100.0, -36.596389293670654, -4.0]\t| 100AvgReward: [-100.0, -225.41143009214545, -31.23]\n",
      "19:22:19\tEpisode\t199\ttimesteps:\t59\tTook\t0.200746 sec - reward:\t[-100.0, -128.5760488808155, -4.0]\t| 100AvgReward: [-100.0, -224.34329787406023, -31.16]\n",
      "19:22:19\tEpisode\t200\ttimesteps:\t84\tTook\t0.258252 sec - reward:\t[-100.0, -20.343143809586763, -13.0]\t| 100AvgReward: [-100.0, -223.94411713397946, -31.19]\n",
      "19:22:19\tEpisode\t201\ttimesteps:\t59\tTook\t0.190533 sec - reward:\t[-100.0, -233.81665098667145, -8.0]\t| 100AvgReward: [-100.0, -225.7423638648435, -31.09]\n",
      "19:22:19\tEpisode\t202\ttimesteps:\t73\tTook\t0.224347 sec - reward:\t[-100.0, -377.62415155768394, -7.0]\t| 100AvgReward: [-100.0, -226.638092847605, -30.9]\n",
      "19:22:20\tEpisode\t203\ttimesteps:\t81\tTook\t0.261374 sec - reward:\t[-100.0, -413.61522203683853, -9.0]\t| 100AvgReward: [-100.0, -228.29159120053868, -29.86]\n",
      "19:22:20\tEpisode\t204\ttimesteps:\t77\tTook\t0.235542 sec - reward:\t[-100.0, 82.14433623291552, -4.0]\t| 100AvgReward: [-100.0, -225.07062998375739, -29.74]\n",
      "19:22:20\tEpisode\t205\ttimesteps:\t82\tTook\t0.235967 sec - reward:\t[-100.0, -320.35849513858557, -6.0]\t| 100AvgReward: [-100.0, -224.38867490543868, -29.42]\n",
      "19:22:20\tEpisode\t206\ttimesteps:\t83\tTook\t0.271264 sec - reward:\t[-100.0, -215.35662522912025, -9.0]\t| 100AvgReward: [-100.0, -226.52118714212324, -29.4]\n",
      "19:22:21\tEpisode\t207\ttimesteps:\t72\tTook\t0.208888 sec - reward:\t[-100.0, -164.81471672654152, -6.0]\t| 100AvgReward: [-100.0, -224.3920087897673, -29.24]\n",
      "19:22:21\tEpisode\t208\ttimesteps:\t60\tTook\t0.203207 sec - reward:\t[-100.0, -73.73331481218338, -7.0]\t| 100AvgReward: [-100.0, -224.46375414772774, -29.12]\n",
      "19:22:21\tEpisode\t209\ttimesteps:\t211\tTook\t0.586996 sec - reward:\t[-100.0, -968.4865247507114, -155.0]\t| 100AvgReward: [-100.0, -230.79940018478896, -30.56]\n",
      "19:22:22\tEpisode\t210\ttimesteps:\t72\tTook\t0.223695 sec - reward:\t[-100.0, -217.1038410589099, -6.0]\t| 100AvgReward: [-100.0, -230.85778940575312, -30.03]\n",
      "19:22:22\tEpisode\t211\ttimesteps:\t57\tTook\t0.186541 sec - reward:\t[-100.0, -177.38737952709198, -3.0]\t| 100AvgReward: [-100.0, -228.43626800840838, -29.91]\n",
      "19:22:22\tEpisode\t212\ttimesteps:\t61\tTook\t0.210802 sec - reward:\t[-100.0, -333.6898583173752, -7.0]\t| 100AvgReward: [-100.0, -232.2510915337794, -29.9]\n",
      "19:22:22\tEpisode\t213\ttimesteps:\t56\tTook\t0.177135 sec - reward:\t[-100.0, -34.39540451206267, -8.0]\t| 100AvgReward: [-100.0, -233.33734054741566, -29.84]\n",
      "19:22:23\tEpisode\t214\ttimesteps:\t84\tTook\t0.258909 sec - reward:\t[-100.0, -258.2103420868516, -3.0]\t| 100AvgReward: [-100.0, -232.849439166683, -29.72]\n",
      "19:22:23\tEpisode\t215\ttimesteps:\t97\tTook\t0.296913 sec - reward:\t[-100.0, -543.5408602952957, -13.0]\t| 100AvgReward: [-100.0, -233.87912534196977, -29.1]\n",
      "19:22:23\tEpisode\t216\ttimesteps:\t58\tTook\t0.170276 sec - reward:\t[-100.0, -88.8396157771349, -7.0]\t| 100AvgReward: [-100.0, -233.50748325218564, -29.08]\n",
      "19:22:23\tEpisode\t217\ttimesteps:\t59\tTook\t0.197739 sec - reward:\t[-100.0, -237.28474533557892, -9.0]\t| 100AvgReward: [-100.0, -232.5941026186489, -28.34]\n",
      "19:22:23\tEpisode\t218\ttimesteps:\t88\tTook\t0.265473 sec - reward:\t[-100.0, -264.9322363138199, -7.0]\t| 100AvgReward: [-100.0, -234.6863609402918, -28.31]\n",
      "19:22:24\tEpisode\t219\ttimesteps:\t79\tTook\t0.252022 sec - reward:\t[-100.0, -245.4819666147232, -8.0]\t| 100AvgReward: [-100.0, -235.7619224945747, -28.29]\n",
      "19:22:24\tEpisode\t220\ttimesteps:\t68\tTook\t0.195905 sec - reward:\t[-100.0, -378.87913060188293, -5.0]\t| 100AvgReward: [-100.0, -238.743673663839, -28.23]\n",
      "19:22:24\tEpisode\t221\ttimesteps:\t58\tTook\t0.202467 sec - reward:\t[-100.0, -255.2463864684105, -2.0]\t| 100AvgReward: [-100.0, -239.58045706818928, -28.11]\n",
      "19:22:24\tEpisode\t222\ttimesteps:\t113\tTook\t0.363163 sec - reward:\t[-100.0, -426.49100248143077, -90.0]\t| 100AvgReward: [-100.0, -243.50330985537846, -28.96]\n",
      "19:22:25\tEpisode\t223\ttimesteps:\t70\tTook\t0.219621 sec - reward:\t[-100.0, -183.58548146486282, -9.0]\t| 100AvgReward: [-100.0, -246.67623823928764, -28.98]\n",
      "19:22:25\tEpisode\t224\ttimesteps:\t53\tTook\t0.166368 sec - reward:\t[-100.0, -284.5148039907217, -6.0]\t| 100AvgReward: [-100.0, -246.16767524297467, -28.98]\n",
      "19:22:25\tEpisode\t225\ttimesteps:\t124\tTook\t0.370342 sec - reward:\t[-100.0, -358.1667065061629, -96.0]\t| 100AvgReward: [-100.0, -244.9141614429152, -28.72]\n",
      "19:22:26\tEpisode\t226\ttimesteps:\t177\tTook\t0.474457 sec - reward:\t[-100.0, 41.69288645926281, -40.0]\t| 100AvgReward: [-100.0, -244.969815127794, -29.08]\n",
      "19:22:26\tEpisode\t227\ttimesteps:\t85\tTook\t0.257764 sec - reward:\t[-100.0, -345.82316371798515, -7.0]\t| 100AvgReward: [-100.0, -248.30041403388634, -29.11]\n",
      "19:22:26\tEpisode\t228\ttimesteps:\t53\tTook\t0.194897 sec - reward:\t[-100.0, -106.07660132087767, -2.0]\t| 100AvgReward: [-100.0, -246.55814398050336, -28.99]\n",
      "19:22:26\tEpisode\t229\ttimesteps:\t91\tTook\t0.267483 sec - reward:\t[-100.0, -570.4929253272712, -13.0]\t| 100AvgReward: [-100.0, -250.97990790445385, -29.02]\n",
      "19:22:27\tEpisode\t230\ttimesteps:\t58\tTook\t0.184278 sec - reward:\t[-100.0, -254.77603536844254, -6.0]\t| 100AvgReward: [-100.0, -253.03151158317954, -29.0]\n",
      "19:22:27\tEpisode\t231\ttimesteps:\t85\tTook\t0.265625 sec - reward:\t[-100.0, -276.0670158267021, -4.0]\t| 100AvgReward: [-100.0, -253.89525138372585, -28.48]\n",
      "19:22:27\tEpisode\t232\ttimesteps:\t56\tTook\t0.188601 sec - reward:\t[-100.0, -0.099215567111969, -8.0]\t| 100AvgReward: [-100.0, -252.26168275989622, -28.43]\n",
      "19:22:27\tEpisode\t233\ttimesteps:\t54\tTook\t0.162855 sec - reward:\t[-100.0, -6.8883760794997215, -4.0]\t| 100AvgReward: [-100.0, -249.02138545494208, -27.92]\n",
      "19:22:27\tEpisode\t234\ttimesteps:\t78\tTook\t0.237111 sec - reward:\t[-100.0, -319.1038922071457, -9.0]\t| 100AvgReward: [-100.0, -250.81369458403117, -27.95]\n",
      "19:22:28\tEpisode\t235\ttimesteps:\t93\tTook\t0.295433 sec - reward:\t[-100.0, -359.64598382264376, -11.0]\t| 100AvgReward: [-100.0, -253.00457162448816, -27.38]\n",
      "19:22:28\tEpisode\t236\ttimesteps:\t80\tTook\t0.235848 sec - reward:\t[-100.0, -239.27513951063156, -8.0]\t| 100AvgReward: [-100.0, -253.7148624623465, -27.33]\n",
      "19:22:28\tEpisode\t237\ttimesteps:\t55\tTook\t0.181168 sec - reward:\t[-100.0, -75.31174778938293, -2.0]\t| 100AvgReward: [-100.0, -255.35983123741025, -27.29]\n",
      "19:22:28\tEpisode\t238\ttimesteps:\t55\tTook\t0.203162 sec - reward:\t[-100.0, -125.38785368204117, -4.0]\t| 100AvgReward: [-100.0, -254.2104975154149, -27.21]\n",
      "19:22:29\tEpisode\t239\ttimesteps:\t84\tTook\t0.255328 sec - reward:\t[-100.0, -530.8549331575632, -6.0]\t| 100AvgReward: [-100.0, -259.22042260906574, -27.21]\n",
      "19:22:29\tEpisode\t240\ttimesteps:\t76\tTook\t0.234056 sec - reward:\t[-100.0, -204.32697474211454, -4.0]\t| 100AvgReward: [-100.0, -258.9433528989079, -27.17]\n",
      "19:22:29\tEpisode\t241\ttimesteps:\t52\tTook\t0.161716 sec - reward:\t[-100.0, -255.7846509218216, 0.0]\t| 100AvgReward: [-100.0, -257.4904421502995, -26.46]\n",
      "19:22:29\tEpisode\t242\ttimesteps:\t54\tTook\t0.201462 sec - reward:\t[-100.0, -100.39743900299072, -5.0]\t| 100AvgReward: [-100.0, -259.18145305158714, -26.4]\n",
      "19:22:29\tEpisode\t243\ttimesteps:\t86\tTook\t0.247454 sec - reward:\t[-100.0, -482.1865023970604, -7.0]\t| 100AvgReward: [-100.0, -265.0610227424107, -26.4]\n",
      "19:22:30\tEpisode\t244\ttimesteps:\t63\tTook\t0.183421 sec - reward:\t[-100.0, -205.91318169236183, -7.0]\t| 100AvgReward: [-100.0, -265.73071275921683, -26.39]\n",
      "19:22:30\tEpisode\t245\ttimesteps:\t59\tTook\t0.200506 sec - reward:\t[-100.0, -34.23933696374297, -4.0]\t| 100AvgReward: [-100.0, -267.63779328569916, -26.39]\n",
      "19:22:30\tEpisode\t246\ttimesteps:\t76\tTook\t0.243007 sec - reward:\t[-100.0, -293.4782855119556, -4.0]\t| 100AvgReward: [-100.0, -267.1608938611127, -26.36]\n",
      "19:22:30\tEpisode\t247\ttimesteps:\t52\tTook\t0.160347 sec - reward:\t[-100.0, -53.708581779152155, -3.0]\t| 100AvgReward: [-100.0, -260.19168715538603, -26.07]\n",
      "19:22:31\tEpisode\t248\ttimesteps:\t84\tTook\t0.243727 sec - reward:\t[-100.0, -287.37737599760294, -7.0]\t| 100AvgReward: [-100.0, -261.7426741369828, -25.35]\n",
      "19:22:31\tEpisode\t249\ttimesteps:\t85\tTook\t0.284484 sec - reward:\t[-100.0, -584.9648424386978, -5.0]\t| 100AvgReward: [-100.0, -265.5023321284368, -25.18]\n",
      "19:22:31\tEpisode\t250\ttimesteps:\t85\tTook\t0.249024 sec - reward:\t[-100.0, -234.05700413882732, -7.0]\t| 100AvgReward: [-100.0, -265.9417422497287, -25.12]\n",
      "19:22:31\tEpisode\t251\ttimesteps:\t86\tTook\t0.250088 sec - reward:\t[-100.0, -340.6394156096503, -8.0]\t| 100AvgReward: [-100.0, -267.9522296764251, -25.1]\n",
      "19:22:32\tEpisode\t252\ttimesteps:\t61\tTook\t0.223385 sec - reward:\t[-100.0, -104.03556449711323, -5.0]\t| 100AvgReward: [-100.0, -265.05585116734875, -24.64]\n",
      "19:22:32\tEpisode\t253\ttimesteps:\t67\tTook\t0.211543 sec - reward:\t[-100.0, -354.6287150979042, -1.0]\t| 100AvgReward: [-100.0, -264.97416083818445, -24.29]\n",
      "19:22:32\tEpisode\t254\ttimesteps:\t66\tTook\t0.211367 sec - reward:\t[-100.0, -130.19093149900436, -6.0]\t| 100AvgReward: [-100.0, -265.60937296157846, -24.03]\n",
      "19:22:32\tEpisode\t255\ttimesteps:\t55\tTook\t0.187364 sec - reward:\t[-100.0, -79.35424464195967, -5.0]\t| 100AvgReward: [-100.0, -265.74609486518574, -24.05]\n",
      "19:22:32\tEpisode\t256\ttimesteps:\t82\tTook\t0.252816 sec - reward:\t[-100.0, -321.754461273551, -5.0]\t| 100AvgReward: [-100.0, -265.99328983711223, -24.04]\n",
      "19:22:33\tEpisode\t257\ttimesteps:\t88\tTook\t0.270456 sec - reward:\t[-100.0, -444.9111841619015, -7.0]\t| 100AvgReward: [-100.0, -264.5693268280677, -23.37]\n",
      "19:22:33\tEpisode\t258\ttimesteps:\t79\tTook\t0.227794 sec - reward:\t[-100.0, -279.80848693847656, -4.0]\t| 100AvgReward: [-100.0, -265.68176591569704, -23.3]\n",
      "19:22:33\tEpisode\t259\ttimesteps:\t87\tTook\t0.283624 sec - reward:\t[-100.0, -303.0849660169333, -70.0]\t| 100AvgReward: [-100.0, -268.38250864342, -23.94]\n",
      "19:22:33\tEpisode\t260\ttimesteps:\t62\tTook\t0.196806 sec - reward:\t[-100.0, -262.94132763147354, -3.0]\t| 100AvgReward: [-100.0, -269.44622172847534, -23.86]\n",
      "19:22:34\tEpisode\t261\ttimesteps:\t62\tTook\t0.201921 sec - reward:\t[-100.0, -100.27890343219042, -3.0]\t| 100AvgReward: [-100.0, -267.847419403737, -23.04]\n",
      "19:22:34\tEpisode\t262\ttimesteps:\t49\tTook\t0.196008 sec - reward:\t[-100.0, -180.1884604692459, -3.0]\t| 100AvgReward: [-100.0, -265.20416336579393, -21.81]\n",
      "19:22:34\tEpisode\t263\ttimesteps:\t63\tTook\t0.204058 sec - reward:\t[-100.0, -160.77606135606766, -3.0]\t| 100AvgReward: [-100.0, -262.77699432240945, -21.66]\n",
      "19:22:34\tEpisode\t264\ttimesteps:\t60\tTook\t0.200544 sec - reward:\t[-100.0, -296.0554950237274, 0.0]\t| 100AvgReward: [-100.0, -265.4772858946971, -21.58]\n",
      "19:22:34\tEpisode\t265\ttimesteps:\t59\tTook\t0.201746 sec - reward:\t[-100.0, -136.4066130835563, -3.0]\t| 100AvgReward: [-100.0, -261.0597946409896, -20.47]\n",
      "19:22:35\tEpisode\t266\ttimesteps:\t71\tTook\t0.232078 sec - reward:\t[-100.0, -401.77898901700974, -6.0]\t| 100AvgReward: [-100.0, -261.64036126747874, -20.37]\n",
      "19:22:35\tEpisode\t267\ttimesteps:\t75\tTook\t0.233943 sec - reward:\t[-100.0, -299.90663635730743, -4.0]\t| 100AvgReward: [-100.0, -264.2628904356077, -20.38]\n",
      "19:22:35\tEpisode\t268\ttimesteps:\t63\tTook\t0.202292 sec - reward:\t[-100.0, -214.76288984715939, -3.0]\t| 100AvgReward: [-100.0, -264.26005506038814, -20.34]\n",
      "19:22:35\tEpisode\t269\ttimesteps:\t53\tTook\t0.162062 sec - reward:\t[-100.0, -34.72187419235706, -4.0]\t| 100AvgReward: [-100.0, -262.103232262285, -20.3]\n",
      "19:22:35\tEpisode\t270\ttimesteps:\t82\tTook\t0.289359 sec - reward:\t[-100.0, -490.2789181768894, -1.0]\t| 100AvgReward: [-100.0, -261.8927780044466, -18.99]\n",
      "19:22:36\tEpisode\t271\ttimesteps:\t57\tTook\t0.179465 sec - reward:\t[-100.0, -70.93857099860907, -4.0]\t| 100AvgReward: [-100.0, -259.85783209145217, -18.42]\n",
      "19:22:36\tEpisode\t272\ttimesteps:\t62\tTook\t0.203127 sec - reward:\t[-100.0, -136.1595890559256, -3.0]\t| 100AvgReward: [-100.0, -258.3369234584659, -17.94]\n",
      "19:22:36\tEpisode\t273\ttimesteps:\t71\tTook\t0.250048 sec - reward:\t[-100.0, -300.65291353315115, -4.0]\t| 100AvgReward: [-100.0, -248.98668732348975, -16.13]\n",
      "19:22:36\tEpisode\t274\ttimesteps:\t54\tTook\t0.171469 sec - reward:\t[-100.0, -22.9238238632679, -4.0]\t| 100AvgReward: [-100.0, -250.0861064771391, -16.14]\n",
      "19:22:36\tEpisode\t275\ttimesteps:\t66\tTook\t0.192261 sec - reward:\t[-100.0, -381.4017502069473, 0.0]\t| 100AvgReward: [-100.0, -248.2376364538647, -15.79]\n",
      "19:22:37\tEpisode\t276\ttimesteps:\t68\tTook\t0.233606 sec - reward:\t[-100.0, -199.08223935961723, -6.0]\t| 100AvgReward: [-100.0, -247.38088164492655, -14.84]\n",
      "19:22:37\tEpisode\t277\ttimesteps:\t69\tTook\t0.240898 sec - reward:\t[-100.0, -177.9153100848198, -2.0]\t| 100AvgReward: [-100.0, -241.46713164684508, -13.77]\n",
      "19:22:37\tEpisode\t278\ttimesteps:\t77\tTook\t0.225792 sec - reward:\t[-100.0, -318.96887280792, -2.0]\t| 100AvgReward: [-100.0, -242.72328889270457, -13.75]\n",
      "19:22:37\tEpisode\t279\ttimesteps:\t75\tTook\t0.229439 sec - reward:\t[-100.0, -417.054904602468, -4.0]\t| 100AvgReward: [-100.0, -240.6856248459514, -12.42]\n",
      "19:22:38\tEpisode\t280\ttimesteps:\t75\tTook\t0.270467 sec - reward:\t[-100.0, -410.2039930820465, -2.0]\t| 100AvgReward: [-100.0, -244.40711121964415, -12.39]\n",
      "19:22:38\tEpisode\t281\ttimesteps:\t69\tTook\t0.22354 sec - reward:\t[-100.0, -281.4841001033783, -7.0]\t| 100AvgReward: [-100.0, -244.44801632630785, -12.42]\n",
      "19:22:38\tEpisode\t282\ttimesteps:\t72\tTook\t0.226489 sec - reward:\t[-100.0, -309.83861833810806, -4.0]\t| 100AvgReward: [-100.0, -247.7812551139589, -12.44]\n",
      "19:22:38\tEpisode\t283\ttimesteps:\t63\tTook\t0.189382 sec - reward:\t[-100.0, -164.860209941864, -1.0]\t| 100AvgReward: [-100.0, -247.95402268397768, -12.4]\n",
      "19:22:39\tEpisode\t284\ttimesteps:\t72\tTook\t0.250032 sec - reward:\t[-100.0, -234.0220843553543, -4.0]\t| 100AvgReward: [-100.0, -248.02077096606752, -12.42]\n",
      "19:22:39\tEpisode\t285\ttimesteps:\t62\tTook\t0.205792 sec - reward:\t[-100.0, -194.29594492912292, -3.0]\t| 100AvgReward: [-100.0, -247.86496622632404, -12.3]\n",
      "19:22:39\tEpisode\t286\ttimesteps:\t62\tTook\t0.203125 sec - reward:\t[-100.0, -67.83991070464253, -6.0]\t| 100AvgReward: [-100.0, -245.23388319580963, -11.86]\n",
      "19:22:39\tEpisode\t287\ttimesteps:\t52\tTook\t0.203165 sec - reward:\t[-100.0, -121.37448143959045, -4.0]\t| 100AvgReward: [-100.0, -242.0747765359204, -11.81]\n",
      "19:22:39\tEpisode\t288\ttimesteps:\t61\tTook\t0.189319 sec - reward:\t[-100.0, -212.78745663166046, -3.0]\t| 100AvgReward: [-100.0, -240.38707105069568, -11.5]\n",
      "19:22:40\tEpisode\t289\ttimesteps:\t59\tTook\t0.187501 sec - reward:\t[-100.0, -262.11870308965445, -9.0]\t| 100AvgReward: [-100.0, -240.22177913849387, -11.43]\n",
      "19:22:40\tEpisode\t290\ttimesteps:\t80\tTook\t0.252111 sec - reward:\t[-100.0, -268.0176457166672, -4.0]\t| 100AvgReward: [-100.0, -239.6314675307754, -11.41]\n",
      "19:22:40\tEpisode\t291\ttimesteps:\t52\tTook\t0.203127 sec - reward:\t[-100.0, -291.78973846137524, -3.0]\t| 100AvgReward: [-100.0, -239.22333151300583, -11.31]\n",
      "19:22:40\tEpisode\t292\ttimesteps:\t80\tTook\t0.252976 sec - reward:\t[-100.0, -410.61150842905045, -6.0]\t| 100AvgReward: [-100.0, -243.13701983117645, -11.27]\n",
      "19:22:40\tEpisode\t293\ttimesteps:\t56\tTook\t0.184422 sec - reward:\t[-100.0, -26.587853010743856, -2.0]\t| 100AvgReward: [-100.0, -243.13922261555825, -11.23]\n",
      "19:22:41\tEpisode\t294\ttimesteps:\t83\tTook\t0.249996 sec - reward:\t[-100.0, -332.10458439588547, -1.0]\t| 100AvgReward: [-100.0, -244.75127787602278, -11.2]\n",
      "19:22:41\tEpisode\t295\ttimesteps:\t61\tTook\t0.221261 sec - reward:\t[-100.0, -392.7218633890152, -2.0]\t| 100AvgReward: [-100.0, -245.96917113357836, -10.46]\n",
      "19:22:41\tEpisode\t296\ttimesteps:\t75\tTook\t0.234338 sec - reward:\t[-100.0, -229.82831498980522, -3.0]\t| 100AvgReward: [-100.0, -244.82041064196878, -9.85]\n",
      "19:22:41\tEpisode\t297\ttimesteps:\t87\tTook\t0.251928 sec - reward:\t[-100.0, -250.53123947232962, -7.0]\t| 100AvgReward: [-100.0, -244.8609124416267, -9.32]\n",
      "19:22:42\tEpisode\t298\ttimesteps:\t77\tTook\t0.265636 sec - reward:\t[-100.0, -502.23036420345306, -7.0]\t| 100AvgReward: [-100.0, -249.51725219072455, -9.35]\n",
      "19:22:42\tEpisode\t299\ttimesteps:\t60\tTook\t0.188209 sec - reward:\t[-100.0, -187.82659924030304, -3.0]\t| 100AvgReward: [-100.0, -250.10975769431943, -9.34]\n",
      "19:22:42\tEpisode\t300\ttimesteps:\t82\tTook\t0.23513 sec - reward:\t[-100.0, -449.957111723721, -9.0]\t| 100AvgReward: [-100.0, -254.40589737346076, -9.3]\n",
      "19:22:42\tEpisode\t301\ttimesteps:\t65\tTook\t0.234424 sec - reward:\t[-100.0, -175.70249821990728, -3.0]\t| 100AvgReward: [-100.0, -253.8247558457931, -9.25]\n",
      "19:22:43\tEpisode\t302\ttimesteps:\t71\tTook\t0.22236 sec - reward:\t[-100.0, -317.0640053600073, -1.0]\t| 100AvgReward: [-100.0, -253.21915438381635, -9.19]\n",
      "19:22:43\tEpisode\t303\ttimesteps:\t75\tTook\t0.224335 sec - reward:\t[-100.0, -297.97796070575714, -4.0]\t| 100AvgReward: [-100.0, -252.06278177050552, -9.14]\n",
      "19:22:43\tEpisode\t304\ttimesteps:\t58\tTook\t0.196897 sec - reward:\t[-100.0, -137.30296635627747, -1.0]\t| 100AvgReward: [-100.0, -254.25725479639746, -9.11]\n",
      "19:22:43\tEpisode\t305\ttimesteps:\t121\tTook\t0.359367 sec - reward:\t[-100.0, -568.3899092264473, -101.0]\t| 100AvgReward: [-100.0, -256.7375689372761, -10.06]\n",
      "19:22:44\tEpisode\t306\ttimesteps:\t68\tTook\t0.206103 sec - reward:\t[-100.0, -327.9121623337269, -1.0]\t| 100AvgReward: [-100.0, -257.86312430832214, -9.98]\n",
      "19:22:44\tEpisode\t307\ttimesteps:\t54\tTook\t0.17189 sec - reward:\t[-100.0, -181.27199852466583, -2.0]\t| 100AvgReward: [-100.0, -258.0276971263034, -9.94]\n",
      "19:22:44\tEpisode\t308\ttimesteps:\t71\tTook\t0.235913 sec - reward:\t[-100.0, -283.0590044260025, -2.0]\t| 100AvgReward: [-100.0, -260.1209540224416, -9.89]\n",
      "19:22:44\tEpisode\t309\ttimesteps:\t56\tTook\t0.188305 sec - reward:\t[-100.0, -189.5628720521927, -5.0]\t| 100AvgReward: [-100.0, -252.3317174954564, -8.39]\n",
      "19:22:44\tEpisode\t310\ttimesteps:\t66\tTook\t0.203127 sec - reward:\t[-100.0, -376.5176326036453, -3.0]\t| 100AvgReward: [-100.0, -253.92585541090375, -8.36]\n",
      "19:22:45\tEpisode\t311\ttimesteps:\t76\tTook\t0.235568 sec - reward:\t[-100.0, -292.4572627544403, -6.0]\t| 100AvgReward: [-100.0, -255.07655424317724, -8.39]\n",
      "19:22:45\tEpisode\t312\ttimesteps:\t88\tTook\t0.281244 sec - reward:\t[-100.0, -674.786247279495, -6.0]\t| 100AvgReward: [-100.0, -258.4875181327984, -8.38]\n",
      "19:22:45\tEpisode\t313\ttimesteps:\t62\tTook\t0.203533 sec - reward:\t[-100.0, -335.4004944562912, -3.0]\t| 100AvgReward: [-100.0, -261.49756903224073, -8.33]\n",
      "19:22:45\tEpisode\t314\ttimesteps:\t62\tTook\t0.188537 sec - reward:\t[-100.0, -250.2117714881897, -3.0]\t| 100AvgReward: [-100.0, -261.4175833262541, -8.33]\n",
      "19:22:45\tEpisode\t315\ttimesteps:\t57\tTook\t0.203162 sec - reward:\t[-100.0, -42.059754371643066, -4.0]\t| 100AvgReward: [-100.0, -256.40277226701755, -8.24]\n",
      "19:22:46\tEpisode\t316\ttimesteps:\t52\tTook\t0.174943 sec - reward:\t[-100.0, -16.767507433891296, -2.0]\t| 100AvgReward: [-100.0, -255.68205118358514, -8.19]\n",
      "19:22:46\tEpisode\t317\ttimesteps:\t48\tTook\t0.171911 sec - reward:\t[-100.0, -106.54879343509674, -2.0]\t| 100AvgReward: [-100.0, -254.37469166458033, -8.12]\n",
      "19:22:46\tEpisode\t318\ttimesteps:\t53\tTook\t0.171839 sec - reward:\t[-100.0, -13.332038700580597, -3.0]\t| 100AvgReward: [-100.0, -251.85868968844792, -8.08]\n",
      "19:22:46\tEpisode\t319\ttimesteps:\t76\tTook\t0.250402 sec - reward:\t[-100.0, -310.9716152101755, -5.0]\t| 100AvgReward: [-100.0, -252.51358617440243, -8.05]\n",
      "19:22:46\tEpisode\t320\ttimesteps:\t65\tTook\t0.20309 sec - reward:\t[-100.0, -153.8102850113064, -4.0]\t| 100AvgReward: [-100.0, -250.26289771849667, -8.04]\n",
      "19:22:47\tEpisode\t321\ttimesteps:\t71\tTook\t0.215917 sec - reward:\t[-100.0, -449.5839188992977, -2.0]\t| 100AvgReward: [-100.0, -252.20627304280555, -8.04]\n",
      "19:22:47\tEpisode\t322\ttimesteps:\t81\tTook\t0.272068 sec - reward:\t[-100.0, -479.7752375006676, -1.0]\t| 100AvgReward: [-100.0, -252.73911539299792, -7.15]\n",
      "19:22:47\tEpisode\t323\ttimesteps:\t80\tTook\t0.24138 sec - reward:\t[-100.0, -379.4139079451561, -6.0]\t| 100AvgReward: [-100.0, -254.69739965780084, -7.12]\n",
      "19:22:47\tEpisode\t324\ttimesteps:\t54\tTook\t0.17098 sec - reward:\t[-100.0, -39.002782724797726, -4.0]\t| 100AvgReward: [-100.0, -252.2422794451416, -7.1]\n",
      "19:22:48\tEpisode\t325\ttimesteps:\t95\tTook\t0.276345 sec - reward:\t[-100.0, -681.9756255447865, -5.0]\t| 100AvgReward: [-100.0, -255.48036863552784, -6.19]\n",
      "19:22:48\tEpisode\t326\ttimesteps:\t72\tTook\t0.242758 sec - reward:\t[-100.0, -325.7091534882784, -1.0]\t| 100AvgReward: [-100.0, -259.15438903500325, -5.8]\n",
      "19:22:48\tEpisode\t327\ttimesteps:\t89\tTook\t0.28695 sec - reward:\t[-100.0, -198.89500856399536, -7.0]\t| 100AvgReward: [-100.0, -257.68510748346336, -5.8]\n",
      "19:22:48\tEpisode\t328\ttimesteps:\t48\tTook\t0.183832 sec - reward:\t[-100.0, -282.030962228775, 0.0]\t| 100AvgReward: [-100.0, -259.44465109254236, -5.78]\n",
      "19:22:49\tEpisode\t329\ttimesteps:\t54\tTook\t0.214295 sec - reward:\t[-100.0, -133.45468926429749, -1.0]\t| 100AvgReward: [-100.0, -255.0742687319126, -5.66]\n",
      "19:22:49\tEpisode\t330\ttimesteps:\t86\tTook\t0.256654 sec - reward:\t[-100.0, -766.9569169282913, -2.0]\t| 100AvgReward: [-100.0, -260.1960775475111, -5.62]\n",
      "19:22:49\tEpisode\t331\ttimesteps:\t104\tTook\t0.290273 sec - reward:\t[-100.0, -378.8530919456389, -90.0]\t| 100AvgReward: [-100.0, -261.22393830870044, -6.48]\n",
      "19:22:49\tEpisode\t332\ttimesteps:\t69\tTook\t0.232273 sec - reward:\t[-100.0, -230.31184569001198, -2.0]\t| 100AvgReward: [-100.0, -263.52606460992945, -6.42]\n",
      "19:22:50\tEpisode\t333\ttimesteps:\t65\tTook\t0.204369 sec - reward:\t[-100.0, -220.89169542491436, -4.0]\t| 100AvgReward: [-100.0, -265.6660978033836, -6.42]\n",
      "19:22:50\tEpisode\t334\ttimesteps:\t85\tTook\t0.25259 sec - reward:\t[-100.0, -648.5534981489182, -5.0]\t| 100AvgReward: [-100.0, -268.9605938628013, -6.38]\n",
      "19:22:50\tEpisode\t335\ttimesteps:\t51\tTook\t0.181653 sec - reward:\t[-100.0, 5.3108725771307945, 0.0]\t| 100AvgReward: [-100.0, -265.3110252988036, -6.27]\n",
      "19:22:50\tEpisode\t336\ttimesteps:\t56\tTook\t0.199572 sec - reward:\t[-100.0, -244.59993267059326, 0.0]\t| 100AvgReward: [-100.0, -265.36427323040317, -6.19]\n",
      "19:22:50\tEpisode\t337\ttimesteps:\t75\tTook\t0.251809 sec - reward:\t[-100.0, -330.6019224524498, -4.0]\t| 100AvgReward: [-100.0, -267.9171749770339, -6.21]\n",
      "19:22:51\tEpisode\t338\ttimesteps:\t71\tTook\t0.20981 sec - reward:\t[-100.0, -228.83921080827713, -2.0]\t| 100AvgReward: [-100.0, -268.9516885482962, -6.19]\n",
      "19:22:51\tEpisode\t339\ttimesteps:\t82\tTook\t0.273558 sec - reward:\t[-100.0, -346.3814726698329, -2.0]\t| 100AvgReward: [-100.0, -267.10695394341894, -6.15]\n",
      "19:22:51\tEpisode\t340\ttimesteps:\t69\tTook\t0.231947 sec - reward:\t[-100.0, -427.9804090857506, -3.0]\t| 100AvgReward: [-100.0, -269.3434882868553, -6.14]\n",
      "19:22:51\tEpisode\t341\ttimesteps:\t75\tTook\t0.250451 sec - reward:\t[-100.0, -356.437468290329, 0.0]\t| 100AvgReward: [-100.0, -270.35001646054036, -6.14]\n",
      "19:22:52\tEpisode\t342\ttimesteps:\t72\tTook\t0.232321 sec - reward:\t[-100.0, -278.6971647143364, -4.0]\t| 100AvgReward: [-100.0, -272.1330137176538, -6.13]\n",
      "19:22:52\tEpisode\t343\ttimesteps:\t63\tTook\t0.22717 sec - reward:\t[-100.0, -154.26067832112312, -3.0]\t| 100AvgReward: [-100.0, -268.85375547689443, -6.09]\n",
      "19:22:52\tEpisode\t344\ttimesteps:\t80\tTook\t0.254146 sec - reward:\t[-100.0, -291.86090794205666, -5.0]\t| 100AvgReward: [-100.0, -269.7132327393914, -6.07]\n",
      "19:22:52\tEpisode\t345\ttimesteps:\t61\tTook\t0.198213 sec - reward:\t[-100.0, -247.58185614831746, -2.0]\t| 100AvgReward: [-100.0, -271.84665793123713, -6.05]\n",
      "19:22:53\tEpisode\t346\ttimesteps:\t61\tTook\t0.222832 sec - reward:\t[-100.0, -221.12994933128357, 0.0]\t| 100AvgReward: [-100.0, -271.12317456943043, -6.01]\n",
      "19:22:53\tEpisode\t347\ttimesteps:\t57\tTook\t0.195671 sec - reward:\t[-100.0, -196.4089236482978, -5.0]\t| 100AvgReward: [-100.0, -272.55017798812185, -6.03]\n",
      "19:22:53\tEpisode\t348\ttimesteps:\t64\tTook\t0.193738 sec - reward:\t[-100.0, -398.00109499692917, -6.0]\t| 100AvgReward: [-100.0, -273.65641517811514, -6.02]\n",
      "19:22:53\tEpisode\t349\ttimesteps:\t53\tTook\t0.191549 sec - reward:\t[-100.0, -263.79942578077316, -3.0]\t| 100AvgReward: [-100.0, -270.4447610115359, -6.0]\n",
      "19:22:53\tEpisode\t350\ttimesteps:\t69\tTook\t0.250296 sec - reward:\t[-100.0, -285.296095892787, -5.0]\t| 100AvgReward: [-100.0, -270.9571519290755, -5.98]\n"
     ]
    }
   ],
   "source": [
    "episodes = 350\n",
    "mname = \"fooo.model\"\n",
    "\n",
    "rewards, avg_rewards, timings = agent.agent_learning(env=env,episodes = episodes, mname=mname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "def display_plot(rewards:list, episodes:int, title:str = \"\"):\n",
    "    \"\"\"\n",
    "    plot the behaviour of the reawards during episodes\n",
    "    \"\"\"\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "    fig.suptitle(title)\n",
    "    ax1.plot(episodes, rewards[0])\n",
    "    ax2.plot(episodes, reward[1])\n",
    "    ax3.plot(episodes, reward[2])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display_plot(rewards, rewards.len, \"Rewards behaviour\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
